{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wB7KigbppvZb"
   },
   "source": [
    "# Fine Tuning the GPT-4 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 8923,
     "status": "ok",
     "timestamp": 1765083089691,
     "user": {
      "displayName": "sai Kesana",
      "userId": "07795278899640606207"
     },
     "user_tz": 360
    },
    "id": "OJjUv_COozHT",
    "outputId": "17f20187-71af-4dc5-8708-063f9e1bbe75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 6929,
     "status": "ok",
     "timestamp": 1765083151740,
     "user": {
      "displayName": "sai Kesana",
      "userId": "07795278899640606207"
     },
     "user_tz": 360
    },
    "id": "mDEjdxAJpftv",
    "outputId": "f6898660-c8d7-4b15-83ca-d52b8bbb61bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xr_PJZNuplcq"
   },
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1560,
     "status": "ok",
     "timestamp": 1765137530498,
     "user": {
      "displayName": "sai Kesana",
      "userId": "07795278899640606207"
     },
     "user_tz": 360
    },
    "id": "WH1F1Tjr8ZjS"
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Dict\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1765137533763,
     "user": {
      "displayName": "sai Kesana",
      "userId": "07795278899640606207"
     },
     "user_tz": 360
    },
    "id": "c1fvPj49_9jM"
   },
   "outputs": [],
   "source": [
    "# need to intialize client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 455,
     "status": "ok",
     "timestamp": 1765083152322,
     "user": {
      "displayName": "sai Kesana",
      "userId": "07795278899640606207"
     },
     "user_tz": 360
    },
    "id": "NFE8Skedp3XX"
   },
   "outputs": [],
   "source": [
    "# loading Data\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "sports_data = fetch_20newsgroups(subset='train', shuffle=True, categories=['rec.sport.baseball', 'rec.sport.hockey'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABnuSGc4qNli"
   },
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1765083152632,
     "user": {
      "displayName": "sai Kesana",
      "userId": "07795278899640606207"
     },
     "user_tz": 360
    },
    "id": "xbjigh-wqZv8",
    "outputId": "33b1b000-3515-4eab-e4ae-73a0c499ecef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: dougb@comm.mot.com (Doug Bank)\n",
      "Subject: Re: Info needed for Cleveland tickets\n",
      "Reply-To: dougb@ecs.comm.mot.com\n",
      "Organization: Motorola Land Mobile Products Sector\n",
      "Distribution: usa\n",
      "Nntp-Posting-Host: 145.1.146.35\n",
      "Lines: 17\n",
      "\n",
      "In article <1993Apr1.234031.4950@leland.Stanford.EDU>, bohnert@leland.Stanford.EDU (matthew bohnert) writes:\n",
      "\n",
      "|> I'm going to be in Cleveland Thursday, April 15 to Sunday, April 18.\n",
      "|> Does anybody know if the Tribe will be in town on those dates, and\n",
      "|> if so, who're they playing and if tickets are available?\n",
      "\n",
      "The tribe will be in town from April 16 to the 19th.\n",
      "There are ALWAYS tickets available! (Though they are playing Toronto,\n",
      "and many Toronto fans make the trip to Cleveland as it is easier to\n",
      "get tickets in Cleveland than in Toronto.  Either way, I seriously\n",
      "doubt they will sell out until the end of the season.)\n",
      "\n",
      "-- \n",
      "Doug Bank                       Private Systems Division\n",
      "dougb@ecs.comm.mot.com          Motorola Communications Sector\n",
      "dougb@nwu.edu                   Schaumburg, Illinois\n",
      "dougb@casbah.acns.nwu.edu       708-576-8207                    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sports_data['data'][0]) # .data gives the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1765083153778,
     "user": {
      "displayName": "sai Kesana",
      "userId": "07795278899640606207"
     },
     "user_tz": 360
    },
    "id": "lmP8TsjGBlgK",
    "outputId": "26d5daa3-867d-48c6-b6d2-4f94a06184d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports_data.target # .target lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1765083154542,
     "user": {
      "displayName": "sai Kesana",
      "userId": "07795278899640606207"
     },
     "user_tz": 360
    },
    "id": "Wd4EKcwcByfE",
    "outputId": "6c766478-c814-42de-90f9-91e553b52b2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rec.sport.baseball', 'rec.sport.hockey']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports_data.target_names # .target_name gives categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1765083155282,
     "user": {
      "displayName": "sai Kesana",
      "userId": "07795278899640606207"
     },
     "user_tz": 360
    },
    "id": "3rtNDN_MrCF7",
    "outputId": "3eacd205-bf34-42de-cbc0-040eed2567c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples: 1197, Baseball examples: 597, Hockey examples: 600\n"
     ]
    }
   ],
   "source": [
    "# Length\n",
    "len_all,len_baseball,len_hockey = len(sports_data['data']),len([e for e in sports_data.target if e==0]),len([e for e in sports_data.target if e == 1])\n",
    "print(f'Total examples: {len_all}, Baseball examples: {len_baseball}, Hockey examples: {len_hockey}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSiyx3vHsvb2"
   },
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ktcb65fDuUh0"
   },
   "source": [
    "we transform the dataset into dataframes i.e, clouumns for prompt and completion [prompt - email from mailing list] [completion - name of sport] . Here we are taking 300 samples for speed of fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1765083158655,
     "user": {
      "displayName": "sai Kesana",
      "userId": "07795278899640606207"
     },
     "user_tz": 360
    },
    "id": "ZQHQLaPiEEUQ"
   },
   "outputs": [],
   "source": [
    "# create prompt and completion pairs\n",
    "def create_prompt_completion_pairs(data):\n",
    "    \"\"\"\n",
    "    Convert raw newsgroup data into prompt-completion format.\n",
    "\n",
    "    For text classification:\n",
    "    - Prompt: The text to classify\n",
    "    - Completion: The category/label\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with 'prompt' and 'completion' columns\n",
    "    \"\"\"\n",
    "    prompts = []\n",
    "    completions = []\n",
    "\n",
    "    for text, x in zip(data.data, data.target):\n",
    "        # Clean and truncate text if too long (GPT-3 has token limits)\n",
    "        text = text.strip()[:2000]  # Limit to ~2000 characters\n",
    "\n",
    "        # Create prompt (the input we'll give to the model)\n",
    "        # Add clear instruction and formatting\n",
    "        prompt = f\"Classify the following text into a category:\\n\\n{text}\\n\\n:\"\n",
    "\n",
    "        # Create completion (the expected output)\n",
    "        # OpenAI recommends adding a space before the completion and \\n at the end\n",
    "        completion = f\" {data.target_names[x].split('.')[-1]}\"\n",
    "\n",
    "        prompts.append(prompt)\n",
    "        completions.append(completion)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'prompt': prompts,\n",
    "        'completion': completions\n",
    "    })\n",
    "\n",
    "    print(f\"\\nCreated {len(df)} prompt-completion pairs\")\n",
    "    print(f\"\\nSample prompt-completion pair:\")\n",
    "    print(f\"Prompt: {df.iloc[0]['prompt'][:200]}...\")\n",
    "    print(f\"Completion: {df.iloc[0]['completion']}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1765083159421,
     "user": {
      "displayName": "sai Kesana",
      "userId": "07795278899640606207"
     },
     "user_tz": 360
    },
    "id": "aDFnr7ygH6FM",
    "outputId": "ee146f56-27eb-4225-ea5b-af79af82fd57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created 1197 prompt-completion pairs\n",
      "\n",
      "Sample prompt-completion pair:\n",
      "Prompt: Classify the following text into a category:\n",
      "\n",
      "From: dougb@comm.mot.com (Doug Bank)\n",
      "Subject: Re: Info needed for Cleveland tickets\n",
      "Reply-To: dougb@ecs.comm.mot.com\n",
      "Organization: Motorola Land Mobile Pr...\n",
      "Completion:  baseball\n"
     ]
    }
   ],
   "source": [
    "sports_df = create_prompt_completion_pairs(sports_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1765083160319,
     "user": {
      "displayName": "sai Kesana",
      "userId": "07795278899640606207"
     },
     "user_tz": 360
    },
    "id": "gYyY7MzsIX9w"
   },
   "outputs": [],
   "source": [
    "# create training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_train_validation(df, test_size=0.2,random_state=42):\n",
    "    \"\"\"\n",
    "    Split dataframe into training and validation sets.\n",
    "    80% train, 20% validation.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        DataFrame with 'prompt' and 'completion' columns\n",
    "    test_size : float\n",
    "        Proportion of data to use for validation (0.1 to 0.2 is typical)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    train_df, val_df : DataFrames\n",
    "    \"\"\"\n",
    "    train_df, val_df = train_test_split(\n",
    "        df,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTraining set size: {len(train_df)} samples\")\n",
    "    print(f\"Validation set size: {len(val_df)} samples\")\n",
    "    print(f\"Split ratio: {(1-test_size)*100:.0f}% train, {test_size*100:.0f}% validation\")\n",
    "\n",
    "    return train_df, val_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1765083161089,
     "user": {
      "displayName": "sai Kesana",
      "userId": "07795278899640606207"
     },
     "user_tz": 360
    },
    "id": "Xmc05ufVPcZq",
    "outputId": "2d706004-c212-4d02-99bd-811474e738cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set size: 957 samples\n",
      "Validation set size: 240 samples\n",
      "Split ratio: 80% train, 20% validation\n"
     ]
    }
   ],
   "source": [
    "#using the above function and split the data\n",
    "train_df, val_df = split_train_validation(sports_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1765083162283,
     "user": {
      "displayName": "sai Kesana",
      "userId": "07795278899640606207"
     },
     "user_tz": 360
    },
    "id": "G762dvMxwPMg"
   },
   "outputs": [],
   "source": [
    "# save dataset as json file\n",
    "# sports_df.to_json(\"dataset.json\",orient = 'records',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1765083165928,
     "user": {
      "displayName": "sai Kesana",
      "userId": "07795278899640606207"
     },
     "user_tz": 360
    },
    "id": "MqYx2wn_KvyB"
   },
   "outputs": [],
   "source": [
    "# prepare jsonl files\n",
    "# using chunks for fast and for large datasets\n",
    "def write_in_chunks(df, filename,chunk_size:int=500):\n",
    "    total_rows = len(df)\n",
    "    \"\"\"\n",
    "    Convert DataFrame to JSONL format required by OpenAI.\n",
    "\n",
    "    Each line in JSONL file must be a JSON object with:\n",
    "    - \"messages\": list of message objects with \"role\" and \"content\"\n",
    "\n",
    "    For fine-tuning, we use the chat format:\n",
    "    - System message (optional): Instructions for the model\n",
    "    - User message: The prompt\n",
    "    - Assistant message: The expected completion\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        DataFrame with 'prompt' and 'completion' columns\n",
    "    filename : str\n",
    "        Output filename for JSONL file\n",
    "    Returns:\n",
    "    --------\n",
    "    filename : str\n",
    "        Output filename for JSONL file\n",
    "    \"\"\"\n",
    "\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for i in range(0, total_rows, chunk_size):\n",
    "          end = min(i+chunk_size,total_rows)\n",
    "          chunk = df.iloc[i:i+chunk_size]\n",
    "\n",
    "          print(f\"processing rows : {i} to {end}\")\n",
    "          for index, row in chunk.iterrows():\n",
    "            # Create the message format for chat models\n",
    "            example = {\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\",\"content\": \"You are a text classifier that categorizes documents into specific categories.\"},\n",
    "                    {\"role\": \"user\", \"content\": row['prompt']},\n",
    "                    {\"role\": \"assistant\",\"content\": row['completion']}\n",
    "                ]\n",
    "            }\n",
    "\n",
    "            # Write as single line JSON\n",
    "            f.write(json.dumps(example) + '\\n')\n",
    "\n",
    "    print(f\"\\nCreated {filename}\")\n",
    "    print(f\"Number of examples: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 154,
     "status": "ok",
     "timestamp": 1765083214128,
     "user": {
      "displayName": "sai Kesana",
      "userId": "07795278899640606207"
     },
     "user_tz": 360
    },
    "id": "GlZ9LAk-stSq",
    "outputId": "3a256d40-078b-4296-8b2d-19c43d367da3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing rows : 0 to 500\n",
      "processing rows : 500 to 957\n",
      "\n",
      "Created train_data_chunks.jsonl\n",
      "Number of examples: 957\n",
      "processing rows : 0 to 240\n",
      "\n",
      "Created validation_data_chunks.jsonl\n",
      "Number of examples: 240\n"
     ]
    }
   ],
   "source": [
    "# Create JSONL files\n",
    "train_file_path = write_in_chunks(train_df, 'train_data_chunks.jsonl')\n",
    "val_file_path = write_in_chunks(val_df, 'validation_data_chunks.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmfFs_-Uw9-l"
   },
   "source": [
    "### Data preparation tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qt8gDyX3wRBh"
   },
   "source": [
    "This tool improve the dataset and split the data into training and validation set.\n",
    "Imrovpements Like:\n",
    "**suffix sepeartor** - suffix between the prompt and completion tells the model that input text is stopped and predict the class.\n",
    "Here since we use same seperater the model is able to learn that it is meant to predict (baseball or Hockey)\n",
    "**whitespace** - tokens are tokenized in a space prefix\n",
    "**Here** it recognise as classification and prepare training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1671,
     "status": "ok",
     "timestamp": 1765084226620,
     "user": {
      "displayName": "sai Kesana",
      "userId": "07795278899640606207"
     },
     "user_tz": 360
    },
    "id": "Rv2K4N3dRygE",
    "outputId": "f7c44fe9-6cfc-4996-ccfc-b879372520cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-YaHs7G6Pk6J8FkdnTRoq1y', bytes=1429811, created_at=1765084226, filename='train_data_chunks.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload files to openai\n",
    "file_response = client.files.create(\n",
    "    file=open(\"/content/train_data_chunks.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "file_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 766,
     "status": "ok",
     "timestamp": 1765084227387,
     "user": {
      "displayName": "sai Kesana",
      "userId": "07795278899640606207"
     },
     "user_tz": 360
    },
    "id": "M7NpP27qvS-a",
    "outputId": "c638343d-6c58-48a9-bb26-ded749f6c5b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-6Epbyz9NVWdfaMtqmiK5d5', bytes=360049, created_at=1765084227, filename='validation_data_chunks.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_response_valid= client.files.create(\n",
    "    file=open(\"/content/validation_data_chunks.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "file_response_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "executionInfo": {
     "elapsed": 1722,
     "status": "ok",
     "timestamp": 1765084231027,
     "user": {
      "displayName": "sai Kesana",
      "userId": "07795278899640606207"
     },
     "user_tz": 360
    },
    "id": "9vPzw7gAvgkB"
   },
   "outputs": [],
   "source": [
    "# creating the fine tuning job\n",
    "fine_tune_response = client.fine_tuning.jobs.create(\n",
    "    training_file=file_response.id,\n",
    "    validation_file=file_response_valid.id,\n",
    "    model=\"gpt-4.1-2025-04-14\",\n",
    "    hyperparameters={\n",
    "        \"n_epochs\": 1,\n",
    "        \"batch_size\" :16,\n",
    "        \"learning_rate_multiplier\": 0.8,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1765084233177,
     "user": {
      "displayName": "sai Kesana",
      "userId": "07795278899640606207"
     },
     "user_tz": 360
    },
    "id": "R9vNXiHLwpgG",
    "outputId": "687bad14-eb72-42f2-8f19-97bf143f94b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-DbWPLJtGNgQ6jyo47z3kpFVU', created_at=1765084230, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size=16, learning_rate_multiplier=0.8, n_epochs=1), model='gpt-4.1-2025-04-14', object='fine_tuning.job', organization_id='org-XobQsGwDmCeEhaPAMiI7Q7cF', result_files=[], seed=1066803071, status='validating_files', trained_tokens=None, training_file='file-YaHs7G6Pk6J8FkdnTRoq1y', validation_file='file-6Epbyz9NVWdfaMtqmiK5d5', estimated_finish=None, integrations=[], metadata=None, method=Method(type='supervised', dpo=None, reinforcement=None, supervised=SupervisedMethod(hyperparameters=SupervisedHyperparameters(batch_size=16, learning_rate_multiplier=0.8, n_epochs=1))), user_provided_suffix=None, usage_metrics=None, shared_with_openai=False, eval_id=None)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tune_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 798,
     "status": "ok",
     "timestamp": 1765137715086,
     "user": {
      "displayName": "sai Kesana",
      "userId": "07795278899640606207"
     },
     "user_tz": 360
    },
    "id": "lWutMo_nKf6p"
   },
   "outputs": [],
   "source": [
    "job = client.fine_tuning.jobs.retrieve(\"ftjob-DbWPLJtGNgQ6jyo47z3kpFVU\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1765137719033,
     "user": {
      "displayName": "sai Kesana",
      "userId": "07795278899640606207"
     },
     "user_tz": 360
    },
    "id": "RleY9TXOZQVZ",
    "outputId": "0067fea8-4381-41b7-c026-499f135f5017"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-DbWPLJtGNgQ6jyo47z3kpFVU', created_at=1765084230, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4.1-2025-04-14:sai-kesana::Ck1vuup9', finished_at=1765086552, hyperparameters=Hyperparameters(batch_size=16, learning_rate_multiplier=0.8, n_epochs=1), model='gpt-4.1-2025-04-14', object='fine_tuning.job', organization_id='org-XobQsGwDmCeEhaPAMiI7Q7cF', result_files=['file-9iiyqpPprZFRpxF8M6p7UH'], seed=1066803071, status='succeeded', trained_tokens=355531, training_file='file-YaHs7G6Pk6J8FkdnTRoq1y', validation_file='file-6Epbyz9NVWdfaMtqmiK5d5', estimated_finish=None, integrations=[], metadata=None, method=Method(type='supervised', dpo=None, reinforcement=None, supervised=SupervisedMethod(hyperparameters=SupervisedHyperparameters(batch_size=16, learning_rate_multiplier=0.8, n_epochs=1))), user_provided_suffix=None, usage_metrics=None, shared_with_openai=False, eval_id=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 200,
     "status": "ok",
     "timestamp": 1765138299560,
     "user": {
      "displayName": "sai Kesana",
      "userId": "07795278899640606207"
     },
     "user_tz": 360
    },
    "id": "mZAnApssaB5p",
    "outputId": "f2efa1aa-ca03-497b-f4a0-275864b5feb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-4prdxCbMgal5KlpX9GuKi8Jt', created_at=1765087323, level='info', message='The job has successfully completed', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-XkaYlIcGaOyNHmMIY7PiMQlI', created_at=1765087318, level='info', message='Usage policy evaluations completed, model is now enabled for sampling', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-KAHJg6Ayv5mjuuXypMsHcqbn', created_at=1765087318, level='info', message='Moderation checks for snapshot ft:gpt-4.1-2025-04-14:sai-kesana::Ck1vuup9 passed.', object='fine_tuning.job.event', data={'blocked': False, 'results': [{'flagged': False, 'category': 'harassment/threatening', 'enforcement': 'blocking'}, {'flagged': False, 'category': 'sexual', 'enforcement': 'blocking'}, {'flagged': False, 'category': 'sexual/minors', 'enforcement': 'blocking'}, {'flagged': False, 'category': 'propaganda', 'enforcement': 'blocking'}, {'flagged': False, 'category': 'hate', 'enforcement': 'blocking'}, {'flagged': False, 'category': 'hate/threatening', 'enforcement': 'blocking'}, {'flagged': False, 'category': 'illicit', 'enforcement': 'blocking'}, {'flagged': False, 'category': 'violence', 'enforcement': 'blocking'}, {'flagged': False, 'category': 'advice', 'enforcement': 'blocking'}, {'flagged': False, 'category': 'self-harm/intent', 'enforcement': 'blocking'}, {'flagged': False, 'category': 'self-harm/instructions', 'enforcement': 'non_blocking'}, {'flagged': False, 'category': 'sensitive', 'enforcement': 'blocking'}, {'flagged': False, 'category': 'highly-sensitive', 'enforcement': 'blocking'}, {'flagged': False, 'category': 'biological threats', 'enforcement': 'blocking'}, {'flagged': False, 'category': 'cyber security threats', 'enforcement': 'blocking'}], 'finetuned_model_checkpoint_id': 'ft:gpt-4.1-2025-04-14:sai-kesana::Ck1vuup9'}, type='moderation_checks'), FineTuningJobEvent(id='ftevent-mIcOXtVIIMLXobsgmBxdTt7D', created_at=1765086555, level='info', message='Evaluating model against our usage policies', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-7SYIgY0HuyfrMdmCAc2qSRcj', created_at=1765086555, level='info', message='New fine-tuned model created', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-YmcJbWuP8mIqUqlmHsNfvlwu', created_at=1765086501, level='info', message='Step 60/60: training loss=0.00, validation loss=0.00, full validation loss=0.00', object='fine_tuning.job.event', data={'step': 60, 'train_loss': 6.162203135318123e-06, 'valid_loss': 4.275639851888021e-05, 'total_steps': 60, 'full_valid_loss': 0.0031324889924791125, 'train_mean_token_accuracy': 1.0, 'valid_mean_token_accuracy': 1.0, 'full_valid_mean_token_accuracy': 0.9986111111111111}, type='metrics'), FineTuningJobEvent(id='ftevent-PwyeM0WXjJyDp2S1sG6iJkH5', created_at=1765086439, level='info', message='Step 59/60: training loss=0.11, validation loss=0.01', object='fine_tuning.job.event', data={'step': 59, 'train_loss': 0.10950645059347153, 'valid_loss': 0.012052456537882486, 'total_steps': 60, 'train_mean_token_accuracy': 0.9791666666666666, 'valid_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-JLnJsNWo63UxHOLRirDvmToU', created_at=1765086429, level='info', message='Step 58/60: training loss=0.33, validation loss=0.00', object='fine_tuning.job.event', data={'step': 58, 'train_loss': 0.3266967833042145, 'valid_loss': 1.5417734781901043e-05, 'total_steps': 60, 'train_mean_token_accuracy': 0.9791666666666666, 'valid_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-Cs3rFrmPSSnhE3P1XHTruGwK', created_at=1765086419, level='info', message='Step 57/60: training loss=0.00, validation loss=0.00', object='fine_tuning.job.event', data={'step': 57, 'train_loss': 4.935264587402344e-05, 'valid_loss': 0.002098560333251953, 'total_steps': 60, 'train_mean_token_accuracy': 1.0, 'valid_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-41tHKzxH50WFhJXTp0iCyAvQ', created_at=1765086410, level='info', message='Step 56/60: training loss=0.43, validation loss=0.00', object='fine_tuning.job.event', data={'step': 56, 'train_loss': 0.42847052216529846, 'valid_loss': 0.0004344781239827474, 'total_steps': 60, 'train_mean_token_accuracy': 0.9791666666666666, 'valid_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-9Ex1R64HPFaR1IaQyt6KKLsb', created_at=1765086400, level='info', message='Step 55/60: training loss=0.00, validation loss=0.00', object='fine_tuning.job.event', data={'step': 55, 'train_loss': 4.259745401213877e-05, 'valid_loss': 6.635983784993489e-05, 'total_steps': 60, 'train_mean_token_accuracy': 1.0, 'valid_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-x81gbCUy9UoxQlQ8tGh7I5DM', created_at=1765086389, level='info', message='Step 54/60: training loss=0.00, validation loss=0.00', object='fine_tuning.job.event', data={'step': 54, 'train_loss': 2.288818359375e-05, 'valid_loss': 0.0013120174407958984, 'total_steps': 60, 'train_mean_token_accuracy': 1.0, 'valid_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-1aDDznh24IiTqJfNLfuOEZZf', created_at=1765086379, level='info', message='Step 53/60: training loss=0.00, validation loss=0.00', object='fine_tuning.job.event', data={'step': 53, 'train_loss': 7.136663043638691e-05, 'valid_loss': 2.2729237874348957e-05, 'total_steps': 60, 'train_mean_token_accuracy': 1.0, 'valid_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-t6JVQhwsegGoMLvwCbaJ1scB', created_at=1765086366, level='info', message='Step 52/60: training loss=0.00, validation loss=0.00', object='fine_tuning.job.event', data={'step': 52, 'train_loss': 0.0010192394256591797, 'valid_loss': 9.775161743164062e-06, 'total_steps': 60, 'train_mean_token_accuracy': 1.0, 'valid_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-YCYi66DkujUt6O8nsFOYVgkX', created_at=1765086356, level='info', message='Step 51/60: training loss=0.00, validation loss=0.00', object='fine_tuning.job.event', data={'step': 51, 'train_loss': 0.00015600521874148399, 'valid_loss': 2.010663350423177e-05, 'total_steps': 60, 'train_mean_token_accuracy': 1.0, 'valid_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-WsTQvZ5Zg122KBODvPg6JeDU', created_at=1765086349, level='info', message='Step 50/60: training loss=0.01, validation loss=0.00', object='fine_tuning.job.event', data={'step': 50, 'train_loss': 0.008692502975463867, 'valid_loss': 0.00013474623362223306, 'total_steps': 60, 'train_mean_token_accuracy': 1.0, 'valid_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-8iz0Q5bH9pIbdt3d9E19YaFM', created_at=1765086336, level='info', message='Step 49/60: training loss=0.00, validation loss=0.03', object='fine_tuning.job.event', data={'step': 49, 'train_loss': 5.3246814786689356e-05, 'valid_loss': 0.02694261074066162, 'total_steps': 60, 'train_mean_token_accuracy': 1.0, 'valid_mean_token_accuracy': 0.9791666666666666}, type='metrics'), FineTuningJobEvent(id='ftevent-o6OiDpqxT8Jyu2u29EmXFZtj', created_at=1765086326, level='info', message='Step 48/60: training loss=0.00, validation loss=0.00', object='fine_tuning.job.event', data={'step': 48, 'train_loss': 2.8928121537319385e-05, 'valid_loss': 8.900960286458334e-06, 'total_steps': 60, 'train_mean_token_accuracy': 1.0, 'valid_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-fOVwph190jYw6Ul8O2p2yHSQ', created_at=1765086316, level='info', message='Step 47/60: training loss=0.00, validation loss=0.00', object='fine_tuning.job.event', data={'step': 47, 'train_loss': 2.3285547285922803e-05, 'valid_loss': 0.00011952718098958333, 'total_steps': 60, 'train_mean_token_accuracy': 1.0, 'valid_mean_token_accuracy': 1.0}, type='metrics'), FineTuningJobEvent(id='ftevent-lD6dyn86En449rYL95E3TYOC', created_at=1765086307, level='info', message='Step 46/60: training loss=0.00, validation loss=0.00', object='fine_tuning.job.event', data={'step': 46, 'train_loss': 7.47839585528709e-05, 'valid_loss': 3.20275624593099e-05, 'total_steps': 60, 'train_mean_token_accuracy': 1.0, 'valid_mean_token_accuracy': 1.0}, type='metrics')], has_more=True, object='list')\n"
     ]
    }
   ],
   "source": [
    "result = client.fine_tuning.jobs.list_events(\"ftjob-DbWPLJtGNgQ6jyo47z3kpFVU\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ltMNKWCTbxMS"
   },
   "outputs": [],
   "source": [
    "save = pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 628
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 142,
     "status": "ok",
     "timestamp": 1765138428360,
     "user": {
      "displayName": "sai Kesana",
      "userId": "07795278899640606207"
     },
     "user_tz": 360
    },
    "id": "1062dceb",
    "outputId": "31d9dab4-16c8-410a-8d43-1e4acf4c1947"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning job events saved to fine_tuning_events.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"display(events_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"ftevent-XkaYlIcGaOyNHmMIY7PiMQlI\",\n          \"ftevent-7SYIgY0HuyfrMdmCAc2qSRcj\",\n          \"ftevent-KAHJg6Ayv5mjuuXypMsHcqbn\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"created_at\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 418,\n        \"min\": 1765086555,\n        \"max\": 1765087323,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1765087323,\n          1765087318,\n          1765086555\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"level\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"info\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"message\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Usage policy evaluations completed, model is now enabled for sampling\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"object\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"fine_tuning.job.event\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"moderation_checks\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-08672223-9375-4a33-a2a9-3679f5c1e1b5\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>level</th>\n",
       "      <th>message</th>\n",
       "      <th>object</th>\n",
       "      <th>data</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ftevent-4prdxCbMgal5KlpX9GuKi8Jt</td>\n",
       "      <td>1765087323</td>\n",
       "      <td>info</td>\n",
       "      <td>The job has successfully completed</td>\n",
       "      <td>fine_tuning.job.event</td>\n",
       "      <td>{}</td>\n",
       "      <td>message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ftevent-XkaYlIcGaOyNHmMIY7PiMQlI</td>\n",
       "      <td>1765087318</td>\n",
       "      <td>info</td>\n",
       "      <td>Usage policy evaluations completed, model is n...</td>\n",
       "      <td>fine_tuning.job.event</td>\n",
       "      <td>{}</td>\n",
       "      <td>message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ftevent-KAHJg6Ayv5mjuuXypMsHcqbn</td>\n",
       "      <td>1765087318</td>\n",
       "      <td>info</td>\n",
       "      <td>Moderation checks for snapshot ft:gpt-4.1-2025...</td>\n",
       "      <td>fine_tuning.job.event</td>\n",
       "      <td>{'blocked': False, 'results': [{'flagged': Fal...</td>\n",
       "      <td>moderation_checks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ftevent-mIcOXtVIIMLXobsgmBxdTt7D</td>\n",
       "      <td>1765086555</td>\n",
       "      <td>info</td>\n",
       "      <td>Evaluating model against our usage policies</td>\n",
       "      <td>fine_tuning.job.event</td>\n",
       "      <td>{}</td>\n",
       "      <td>message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ftevent-7SYIgY0HuyfrMdmCAc2qSRcj</td>\n",
       "      <td>1765086555</td>\n",
       "      <td>info</td>\n",
       "      <td>New fine-tuned model created</td>\n",
       "      <td>fine_tuning.job.event</td>\n",
       "      <td>{}</td>\n",
       "      <td>message</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08672223-9375-4a33-a2a9-3679f5c1e1b5')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-08672223-9375-4a33-a2a9-3679f5c1e1b5 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-08672223-9375-4a33-a2a9-3679f5c1e1b5');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-df6ae1ba-0ef9-4d57-97e2-e2030571852a\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df6ae1ba-0ef9-4d57-97e2-e2030571852a')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-df6ae1ba-0ef9-4d57-97e2-e2030571852a button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                 id  created_at level  \\\n",
       "0  ftevent-4prdxCbMgal5KlpX9GuKi8Jt  1765087323  info   \n",
       "1  ftevent-XkaYlIcGaOyNHmMIY7PiMQlI  1765087318  info   \n",
       "2  ftevent-KAHJg6Ayv5mjuuXypMsHcqbn  1765087318  info   \n",
       "3  ftevent-mIcOXtVIIMLXobsgmBxdTt7D  1765086555  info   \n",
       "4  ftevent-7SYIgY0HuyfrMdmCAc2qSRcj  1765086555  info   \n",
       "\n",
       "                                             message                 object  \\\n",
       "0                 The job has successfully completed  fine_tuning.job.event   \n",
       "1  Usage policy evaluations completed, model is n...  fine_tuning.job.event   \n",
       "2  Moderation checks for snapshot ft:gpt-4.1-2025...  fine_tuning.job.event   \n",
       "3        Evaluating model against our usage policies  fine_tuning.job.event   \n",
       "4                       New fine-tuned model created  fine_tuning.job.event   \n",
       "\n",
       "                                                data               type  \n",
       "0                                                 {}            message  \n",
       "1                                                 {}            message  \n",
       "2  {'blocked': False, 'results': [{'flagged': Fal...  moderation_checks  \n",
       "3                                                 {}            message  \n",
       "4                                                 {}            message  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extract event data from the result object\n",
    "events_data = []\n",
    "for event in result.data:\n",
    "    event_dict = event.model_dump() # Convert Pydantic model to dictionary\n",
    "    events_data.append(event_dict)\n",
    "\n",
    "# Create a DataFrame from the events data\n",
    "events_df = pd.DataFrame(events_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_filename = \"fine_tuning_events.csv\"\n",
    "events_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"Fine-tuning job events saved to {csv_filename}\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "display(events_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5pYPxVs8dyzA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOWIGiWIPo1K7ck+BUoqTUW",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
